{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00cfd591",
   "metadata": {},
   "source": [
    "# Crear blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e173db",
   "metadata": {},
   "source": [
    "Per verificar que datasets.ods i el notebook estan a la llista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb13114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\UX433\\miniconda3\\envs\\myenv\\python.exe\n",
      "Directori de treball: c:\\Users\\UX433\\OneDrive\\Escritorio\\networkalignment\n",
      "Llistat d'arxius a la carpeta:\n",
      " - .git\n",
      " - A2_blueprint.npy\n",
      " - A_test_equiv.npy\n",
      " - C-el_k4_Synthetic- No groups - Simoultenously.ipynb\n",
      " - Hs_base0.npy\n",
      " - Hs_base1.npy\n",
      " - Hs_synthetic_paper.npy\n",
      " - L_latent_from_pq.npy\n",
      " - L_latent_repo_exact_errors.npy\n",
      " - Matriz_epochs_A.pickle\n",
      " - Syntetic_succesive_tot_0.pickle\n",
      " - codienbrut.ipynb\n",
      " - crear_blueprint.ipynb\n",
      " - datasets.ods\n",
      " - energies_base0.npy\n",
      " - energies_base1.npy\n",
      " - energy_pipeline_summary.npy\n",
      " - environment.yml\n",
      " - synthetic_paper.npy\n",
      " - synthetic_repo_errors.npy\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print(\"Python executable:\", sys.executable)     # mostra el Python que corre (ha de ser el env activat)\n",
    "print(\"Directori de treball:\", os.getcwd())    # carpeta del repo\n",
    "print(\"Llistat d'arxius a la carpeta:\")\n",
    "for f in sorted(os.listdir('.')):\n",
    "    print(\" -\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47175c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from numba import jit, njit\n",
    "from numba.types import bool_, int_, float32\n",
    "from math import comb\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4265c",
   "metadata": {},
   "source": [
    "### Llegir fulls de càlcul "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2109afac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: 0 size (227, 183)\n",
      "Read: 1 size (227, 183)\n",
      "Read: 2 size (227, 183)\n",
      "Read: 3 size (227, 183)\n",
      "Read: 4 size (227, 183)\n",
      "Read: 5 size (227, 183)\n",
      "Read: 6 size (227, 183)\n",
      "Read: 7 size (227, 183)\n"
     ]
    }
   ],
   "source": [
    "### Open the files\n",
    "fulls = 8\n",
    "#n_grupo = 4 - ara no estic fent servir grups\n",
    "\n",
    "d = {} #crea un diccionari per emmagatzemar DataFrames(taules de memòria)\n",
    "D = \"Dataset\" #prefix del nom de les fulles — al excel es diuen Dataset1, Dataset2, ...\n",
    "for i in range(0,fulls): #recorro 0...7\n",
    "    d[\"group\" + str(i)] = pd.read_excel(\"datasets.ods\", sheet_name=D+str(i+1)) #el que al diccionari serà gorup 0, sera el meu Dataset1\n",
    "    # hem assignat al diccionari: d[\"group0\"] = <taula Dataset1> \n",
    "    print('Read:',i, 'size', d[\"group\" + str(i)].shape) #volem imprimir el nre de files i columnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6970a48d",
   "metadata": {},
   "source": [
    "### Passar a matriu i binaritzem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a1aef",
   "metadata": {},
   "source": [
    "Consideracions a tenir en compte. Primer, treiem les 3 primeres files i columnes de cada full de càlcul perquè a l'excel contenen etiquetes, no dades. En segon lloc, tenim 227 diles i 183 columnes. El que fem és forçar una matriu quadrada nre.filesxnre.files, de manera que, com la matriu inicial eren zeros, copio les columnes existets i deixo la resta plenes de zeros. Això podria donar error. NOTA: Els datasets compten la primera columna com títols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be74200",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hipermatrix M with the data (Only the synapses) \n",
    "rows = d[\"group\" + str(i)].shape[0] - 3\n",
    "columns = d[\"group\" + str(i)].shape[1] - 3 #les tres primeres files i columnes no contenen dades\n",
    "\n",
    "M = np.zeros((fulls,rows,columns))\n",
    "for i in range(0, fulls):\n",
    "    Data = d['group' + str(i)]\n",
    "    M[i,:,:] = Data.iloc[3:,3:]\n",
    "    \n",
    "## Since we work with same number of nodes, we want them equal and square (zeros when no connections)\n",
    "M_square = np.zeros((fulls, rows, rows))#creo matriu quadrada\n",
    "M_square[:,:, 0:columns] = M[:,:,:] #copies les columnes existents (0..179) per deixar zeros en les restants (180..223).\n",
    "\n",
    "## Binarization: No weights\n",
    "#Lo queremos BINARIO, ignorando su peso (Luego pensar cómo se haría con el peso)\n",
    "M_square_bin = np.zeros((fulls,rows,rows))\n",
    "for i in range(fulls):\n",
    "    for j in range(rows):\n",
    "        for k in range(columns):\n",
    "            if (M[i,j,k] >= 1):\n",
    "                M_square_bin[i,j,k] = 1\n",
    "                \n",
    "Nx = rows # Number of nodes (we imposed rows == columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38907c1",
   "metadata": {},
   "source": [
    "### Comprovació de l’estructura dels fulls de càlcul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d311e",
   "metadata": {},
   "source": [
    "Vull assegurar-me de que la neteja dels Datasets (primeres 3 files i columnes) està feta correctament. Nota: Els Datasets prenen la primera fila com un Títol  ('Pre', en aquest cas). Per tant, realment n'estic esborrant 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a76e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original group7: (227, 183)\n",
      "\n",
      "Column names (first 12):\n",
      " Index(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Pre', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
      "       'Unnamed: 10', 'Unnamed: 11'],\n",
      "      dtype='object')\n",
      "\n",
      "Primeres 8 files i 8 columnes (sense transformar):\n",
      "  Unnamed: 0 Unnamed: 1 Unnamed: 2      Pre Unnamed: 4 Unnamed: 5 Unnamed: 6  \\\n",
      "0        NaN        NaN        NaN  Sensory        NaN        NaN        NaN   \n",
      "1        NaN        NaN        NaN     ADFL       ADFR       ADLL       ADLR   \n",
      "2        NaN        NaN        NaN      NaN        NaN        NaN        NaN   \n",
      "3       Post    Sensory       ADFL        0          0          0          0   \n",
      "4        NaN        NaN       ADFR        0          0          0          0   \n",
      "5        NaN        NaN       ADLL        0          0          0          0   \n",
      "6        NaN        NaN       ADLR        0          0          0          0   \n",
      "7        NaN        NaN       AFDL        0          0          0          0   \n",
      "\n",
      "  Unnamed: 7  \n",
      "0        NaN  \n",
      "1       AFDL  \n",
      "2        NaN  \n",
      "3          0  \n",
      "4          0  \n",
      "5          0  \n",
      "6          0  \n",
      "7          0  \n"
     ]
    }
   ],
   "source": [
    "# inspecció ràpida d'un full de càlcul (group 7-->Dataset8)\n",
    "df7 = d['group7']\n",
    "print(\"Shape original group7:\", df7.shape)\n",
    "print(\"\\nColumn names (first 12):\\n\", df7.columns[:12])\n",
    "print(\"\\nPrimeres 8 files i 8 columnes (sense transformar):\")\n",
    "print(df7.iloc[:8, :8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5191d3",
   "metadata": {},
   "source": [
    "## Escollir quin és el dataset A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ef07f",
   "metadata": {},
   "source": [
    "Sabem (per la informació del paper) que A2 té aproximadament 2186 arestes (edges), comprovem si el Dataset8 concorda amb aquestes dades, mirem cada dataset (recordem que group0-->Dataset1, group1-->Dataset2, ...).\n",
    "\n",
    "NOTA: A més sospitem que el Dataset8 és el que conté les dades de A2 perquè al repo de la Teresa es pren A2 com a Blueprint fent M_square_bin[-1] que correspon a l'últim element de l'array, és a dir, M_square_bin[7], que correspon a group7--> Dataset8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c4042",
   "metadata": {},
   "source": [
    "### Coprovació de que Dataset8 correspon a A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d1b9b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 775.0\n",
      "1 986.0\n",
      "2 1012.0\n",
      "3 1136.0\n",
      "4 1515.0\n",
      "5 1525.0\n",
      "6 2202.0\n",
      "7 2186.0\n"
     ]
    }
   ],
   "source": [
    "# Veure quants edges té cada dataset\n",
    "for i in range(8):\n",
    "    print(i, M_square_bin[i].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634a9b4",
   "metadata": {},
   "source": [
    "## Guardar A2 com blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610a29b",
   "metadata": {},
   "source": [
    "Volem crear i guardar el blueprint A2 (Dataset8 = group7 = M_square_bin[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a5c5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2 creat\n",
      "Files i columnes A2 (224, 224)\n",
      "Arestes 2186\n",
      "Guardat com A2_blueprint\n"
     ]
    }
   ],
   "source": [
    "#Seleccionem A2, és a dir, el dataset8\n",
    "A2=M_square_bin[-1].copy()\n",
    "#Fem comprovacions\n",
    "print(\"A2 creat\")\n",
    "print(\"Files i columnes A2\", A2.shape)\n",
    "print(\"Arestes\", int(A2.sum()))\n",
    "#guardem\n",
    "np.save(\"A2_blueprint.npy\", A2)\n",
    "print(\"Guardat com A2_blueprint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463e263",
   "metadata": {},
   "source": [
    "# Generar xarxes amb error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b113626",
   "metadata": {},
   "source": [
    "Dues maneres, fixar un nombre d'errors (com es fa al codi de la Teresa) o fer servir p i q (probabilitats de copiar malament un link/no-link). Farem totes dues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbf724",
   "metadata": {},
   "source": [
    "### ESBORRAR AIXÒ: Veure d'on sortien els errors q feia servir Teresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89bab6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges 2186 zeros 47990\n",
      "q_equiv = 0.1495882891125343\n",
      "p_equiv = 0.00681391956657637\n"
     ]
    }
   ],
   "source": [
    "L = np.load(\"A2_blueprint.npy\")\n",
    "Nx = L.shape[0]\n",
    "edges = int(L.sum())\n",
    "zeros = Nx*Nx - edges\n",
    "e_error = 327\n",
    "z_error = 327\n",
    "q_equiv = e_error / edges\n",
    "p_equiv = z_error / zeros\n",
    "print(\"edges\", edges, \"zeros\", zeros)\n",
    "print(\"q_equiv =\", q_equiv)\n",
    "print(\"p_equiv =\", p_equiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6c5b4",
   "metadata": {},
   "source": [
    "Hem vist que p i q del repositori son practicament els mateixos del paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ac67e",
   "metadata": {},
   "source": [
    "### Càlcul de nombre d'errors equivalents per p i q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b7136c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint A2 carregat correctament.\n",
      "Mida: (224, 224)\n",
      "Nombre d'enllaços (1’s): 2186\n"
     ]
    }
   ],
   "source": [
    "# Carrega el blueprint A2 desat\n",
    "L = np.load(\"A2_blueprint.npy\")\n",
    "\n",
    "Nx = L.shape[0]\n",
    "\n",
    "print(\"Blueprint A2 carregat correctament.\")\n",
    "print(\"Mida:\", L.shape)\n",
    "print(\"Nombre d'enllaços (1’s):\", int(L.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "304c50fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 335\n"
     ]
    }
   ],
   "source": [
    "# Errors deduits dels valors del paper\n",
    "edges_A2 = L.sum()\n",
    "zeros_A2 = Nx*Nx - edges_A2\n",
    "\n",
    "q_paper = 0.15\n",
    "p_paper = 0.007\n",
    "\n",
    "errors_esborrar = int(q_paper * edges_A2)\n",
    "errors_crear = int(p_paper * zeros_A2)\n",
    "\n",
    "print(errors_esborrar, errors_crear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc99760",
   "metadata": {},
   "source": [
    "No són exactament els mateixos, suposo que això es deu a què al repo es fan servir p i q que no quadren exactament amb els del paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c889cf9",
   "metadata": {},
   "source": [
    "(Esborrar això) ara faré el mateix però amb els p i q que he deduit del codi de la teresa, per veure si em surt el mateix nre, d'errors que ella ha fet servir (327,327) i comprovar validesa de l'anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f0ea094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 327\n"
     ]
    }
   ],
   "source": [
    "# Errors deduits dels valors del paper\n",
    "edges_A2 = L.sum()\n",
    "zeros_A2 = Nx*Nx - edges_A2\n",
    "\n",
    "errors_esborrar_teresa = int(q_equiv * edges_A2)\n",
    "errors_crear_teresa = int(p_equiv * zeros_A2)\n",
    "\n",
    "print(errors_esborrar_teresa, errors_crear_teresa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4fec7",
   "metadata": {},
   "source": [
    "Sí, el nombre d'errors quadra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fdf74",
   "metadata": {},
   "source": [
    "# Generar xarxes amb nombre d'errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf29cec",
   "metadata": {},
   "source": [
    "Ara estem generant xarxes com es feia al repositori, amb el mateix nombre d'errors exacte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fddc963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint A2 carregat: shape (224, 224) edges: 2186\n",
      "Edges A2: 2186 Zeros A2: 47990\n",
      "Xarxa 0: Edges = 2186, Errors esborrant = 327, Errors creant = 327\n",
      "Xarxa 1: Edges = 2186, Errors esborrant = 327, Errors creant = 327\n",
      "\n",
      "Guardades les xarxes amb errors exactes a: synthetic_repo_errors.npy\n"
     ]
    }
   ],
   "source": [
    "# === Generar xarxes amb errors exactes (estil del repo) ===\n",
    "\n",
    "K = 2             # nombre de xarxes a generar\n",
    "e_error = 327       # errors esborrant enllaços\n",
    "z_error = 327       # errors creant enllaços\n",
    "\n",
    "# Carregar blueprint si cal\n",
    "if 'L' not in globals():\n",
    "    print(\"No hi ha L a la memòria, carregant A2_blueprint.npy ...\")\n",
    "    L = np.load(\"A2_blueprint.npy\")\n",
    "\n",
    "Nx = L.shape[0]\n",
    "print(\"Blueprint A2 carregat: shape\", L.shape, \"edges:\", int(L.sum()))\n",
    "\n",
    "# Preparar output\n",
    "A_repo = np.zeros((K, Nx, Nx), dtype=int)\n",
    "rng = np.random.default_rng(42)  # llavor fixa\n",
    "\n",
    "edges_total = int(L.sum())\n",
    "zeros_total = Nx * Nx - edges_total\n",
    "\n",
    "print(\"Edges A2:\", edges_total, \"Zeros A2:\", zeros_total)\n",
    "\n",
    "# Comprovacions\n",
    "if e_error > edges_total:\n",
    "    raise ValueError(f\"e_error ({e_error}) > nombre d'enllaços ({edges_total})\")\n",
    "if z_error > zeros_total:\n",
    "    raise ValueError(f\"z_error ({z_error}) > nombre de zeros ({zeros_total})\")\n",
    "\n",
    "for m in range(K):\n",
    "    A = L.copy().astype(int)\n",
    "    A_flat = A.reshape(Nx*Nx)\n",
    "\n",
    "    ones_idx = np.where(A_flat == 1)[0]\n",
    "    zeros_idx = np.where(A_flat == 0)[0]\n",
    "\n",
    "    flip_ones = rng.choice(ones_idx, size=e_error, replace=False)\n",
    "    flip_zeros = rng.choice(zeros_idx, size=z_error, replace=False)\n",
    "\n",
    "    A_flat[flip_ones] = 0\n",
    "    A_flat[flip_zeros] = 1\n",
    "\n",
    "    A = A_flat.reshape(Nx, Nx)\n",
    "    A_repo[m] = A\n",
    "\n",
    "    errors_removed = edges_total - np.sum((A == 1) & (L == 1))\n",
    "    errors_added = np.sum((A == 1) & (L == 0))\n",
    "\n",
    "    print(f\"Xarxa {m}: Edges = {int(A.sum())}, Errors esborrant = {errors_removed}, Errors creant = {errors_added}\")\n",
    "\n",
    "# Guardar a disc\n",
    "out_name = \"synthetic_repo_errors.npy\"\n",
    "np.save(out_name, A_repo)\n",
    "print(\"\\nGuardades les xarxes amb errors exactes a:\", out_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92add2",
   "metadata": {},
   "source": [
    "# Generar xarxes amb p i q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b840586",
   "metadata": {},
   "source": [
    "Ara volem comprovar el nombre d'enllaços que s'han creat (p·zeros ≈ 0.007·48000 ≈ 330–350 nous) i esborrat (q·edges ≈ 0.15·2186 ≈ 327–330 enllaços)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a40bf",
   "metadata": {},
   "source": [
    "El que estic fent aquí no és modificar el blueprint amb errors, no reconstruir des de 0. No estic recreant la matriu probabilisticament partint d'una matriu de 0s. \n",
    "Aqui la matriu L comença tocada i només altero alguns elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9447b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xarxes generades amb p i q del paper:\n",
      "(2, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "num_networks = 2\n",
    "A_test = np.zeros((num_networks, Nx, Nx)) #crea un array 3D ple de zeros\n",
    "\n",
    "p = p_paper\n",
    "q = q_paper\n",
    "\n",
    "np.random.seed(1) #fixo la llavor de les xarxes random generades pq sino cada execucio em genera xarxes diferents\n",
    "\n",
    "for k in range(num_networks):\n",
    "    A_copy = L.copy() #deep copy de L, però no comparteixen memòria. modificar a.copy no modifica L\n",
    "    for i in range(Nx):\n",
    "        for j in range(Nx):\n",
    "            if L[i,j] == 1:\n",
    "                # enllaç existent -> pot ser esborrat\n",
    "                if np.random.rand() < q: #genero aleatori entre 0 i 1\n",
    "                    A_copy[i,j] = 0\n",
    "            else:\n",
    "                # posició buida -> pot crear-se un fals\n",
    "                if np.random.rand() < p:\n",
    "                    A_copy[i,j] = 1\n",
    "    A_test[k,:,:] = A_copy #guardo cada xarxa k generada.\n",
    "    # per cada k (ie per cada xarxa), es comença de zero fent una còpia nova i completa de L.\n",
    "\n",
    "\n",
    "print(\"Xarxes generades amb p i q del paper:\")\n",
    "print(A_test.shape)\n",
    "np.save(\"synthetic_paper.npy\", A_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb6fa2",
   "metadata": {},
   "source": [
    "Si ho vull fer tal com em va dir la marta, emplenant una matriu feta de 0s seria aixi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49a162bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xarxes generades amb p i q del paper partint d'una de 0s (recrear probabilisticament):\n",
      "(2, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A_test_0 = np.zeros((num_networks, Nx, Nx))\n",
    "np.random.seed(1)\n",
    "\n",
    "for k in range(num_networks):\n",
    "    A_copy_0 = np.zeros_like(L)   # matriu tota de 0\n",
    "\n",
    "    for i in range(Nx):\n",
    "        for j in range(Nx):\n",
    "\n",
    "            if L[i, j] == 1:\n",
    "                # Enllaç existent\n",
    "                if np.random.rand() < q:\n",
    "                    A_copy_0[i, j] = 0        # No copio (error d'esborrat)\n",
    "                else:\n",
    "                    A_copy_0[i, j] = 1        # Copio\n",
    "            else:\n",
    "                # No enllaç\n",
    "                if np.random.rand() < p:\n",
    "                    A_copy_0[i, j] = 1        # Fals positiu\n",
    "                else:\n",
    "                    A_copy_0[i, j] = 0        # Copio (0)\n",
    "\n",
    "    A_test_0[k] = A_copy_0\n",
    "print(\"Xarxes generades amb p i q del paper partint d'una de 0s (recrear probabilisticament):\")\n",
    "print(A_test_0.shape)\n",
    "np.save(\"synthetic_paper_0.npy\", A_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b0c980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint (A2) edges: 2186\n",
      "Blueprint zeros: 47990\n",
      "\n",
      "Xarxa 0:\n",
      "  Edges: 2207\n",
      "  Errors esborrant: 320\n",
      "  Errors creant: 341\n",
      "\n",
      "Xarxa 1:\n",
      "  Edges: 2174\n",
      "  Errors esborrant: 333\n",
      "  Errors creant: 321\n"
     ]
    }
   ],
   "source": [
    "# Comprovació del nombre d’enllaços final\n",
    "original_edges = int(L.sum())\n",
    "zeros_original = Nx*Nx - original_edges\n",
    "\n",
    "print(\"Blueprint (A2) edges:\", original_edges)\n",
    "print(\"Blueprint zeros:\", zeros_original)\n",
    "\n",
    "for k in range(num_networks):\n",
    "    edges_new = int(A_test[k].sum())\n",
    "    print(f\"\\nXarxa {k}:\")\n",
    "    print(\"  Edges:\", edges_new)\n",
    "\n",
    "    # errors equivalents\n",
    "    errors_esborrats = original_edges - np.sum((A_test[k] == 1) & (L == 1))\n",
    "    errors_creats = np.sum((A_test[k] == 1) & (L == 0))\n",
    "\n",
    "    print(\"  Errors esborrant:\", errors_esborrats)\n",
    "    print(\"  Errors creant:\", errors_creats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c7afe",
   "metadata": {},
   "source": [
    "## Funcions d'energia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6df48",
   "metadata": {},
   "source": [
    "Aquí enganxo les funcions d'energia del repositori del paper, del notebook \"C-el_k4_Synthetic-No groups...\", ja que son les mateixes que he de fer servir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47311f22",
   "metadata": {},
   "source": [
    "No considerem grups, per tant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3e81b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups = 1 #considerem que els nodes pertanyen a un únic grup\n",
    "start_groups = np.zeros(1) #indica on comença cada grup\n",
    "end_groups = np.zeros(1) + Nx #indica on acaba\n",
    "size_groups = np.zeros(1) + Nx\n",
    "\n",
    "start_groups, end_groups, size_groups = start_groups.astype(int), end_groups.astype(int), size_groups.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d37d46",
   "metadata": {},
   "source": [
    "Aquestes son les funcions d'energia tal qual com estan al repo del paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "017ad3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(nopython = True)\n",
    "def hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta):\n",
    "#calcula l’energia H com a suma de dues log-Beta (usant lgamma) i torna - (H1 + H0) \n",
    "    \n",
    "    print(\"\\n---- DINS HAMILTONIAN ----\")\n",
    "    print(\"Edges_NoL:\", Edges_NoL)\n",
    "    print(\"Edges_L:\", Edges_L)\n",
    "    print(\"overlap_0:\", overlap_0)\n",
    "    print(\"overlap_1:\", overlap_1)\n",
    "    print(\"alpha:\", alpha, \"beta:\", beta)\n",
    "    \n",
    "    \n",
    "    \n",
    "    A_1 = overlap_1 + alpha\n",
    "    B_1 = (Edges_L - overlap_1 + beta)\n",
    "    C_1 = Edges_L + alpha + beta\n",
    "    \n",
    "    A_0 = overlap_0 + alpha\n",
    "    B_0 = (Edges_NoL - overlap_0 + beta)\n",
    "    C_0 = Edges_NoL + alpha + beta\n",
    "    \n",
    "    #  [ math.lgamma(n+1) == log(n!) ]\n",
    "    H1 = math.lgamma(A_1)+ math.lgamma(B_1) - math.lgamma(C_1) \n",
    "    H0 = math.lgamma(A_0)+ math.lgamma(B_0) - math.lgamma(C_0) \n",
    "    \n",
    "    H = -(H1 + H0)\n",
    "    print(\"A_1,B_1,C_1 =\", A_1, B_1, C_1)\n",
    "    print(\"A_0,B_0,C_0 =\", A_0, B_0, C_0)\n",
    "    return H\n",
    "\n",
    "    \n",
    "    \n",
    "# @jit(nopython=True)\n",
    "def overlap_total_prob(L_f, A_f, P_inv_f):\n",
    "    #corre la blueprint L_f (de mida Ny x Nx) i per cada observació k suma 2 quantitats:\n",
    "\n",
    "    print(\"\\n=== DINS overlap_total_prob ===\")\n",
    "    print(\"L_f shape:\", L_f.shape)\n",
    "    print(\"A_f shape:\", A_f.shape)\n",
    "    print(\"P_inv_f shape:\", P_inv_f.shape)\n",
    "\n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    \n",
    "    ovlp_0 = np.zeros((K)) #nombre de posicions on L==0 i A_k també és 0.\n",
    "    ovlp_1 = np.zeros((K)) #nombre de posicions on L==1 i A_k (mapejat per P_inv) també és 1.\n",
    "    for k in range(0,K):\n",
    "        print(f\"\\n-- Xarxa k = {k} --\")\n",
    "        for f in range(0,Ny): \n",
    "            for c in range(0,Nx):\n",
    "                p_f=int(P_inv_f[k,f])\n",
    "                p_c=int(P_inv_f[k,c])  \n",
    "                \n",
    "                if f < 3 and c < 3:    # evitar imprimir massa\n",
    "                    print(f\"f={f}, c={c}  ->  mapped to (p_f={p_f}, p_c={p_c})\")\n",
    "\n",
    "\n",
    "                valor_L, valor_A = L_f[f,c], A_f[k,p_f,p_c]\n",
    "\n",
    "                if f < 3 and c < 3:\n",
    "                    print(f\"L={valor_L}, A={valor_A}\")\n",
    "                \n",
    "                ovlp_0[k] = ovlp_0[k] + (1-valor_L)*(1-valor_A )\n",
    "                ovlp_1[k] = ovlp_1[k] + valor_L*valor_A\n",
    "                \n",
    "    print(\"SUMA FINAL ovlp_0:\", sum(ovlp_0))\n",
    "    print(\"SUMA FINAL ovlp_1:\", sum(ovlp_1))\n",
    "\n",
    "    ovlp_1 = int(sum(ovlp_1)) #potser els que ens interesa és el de cada xarxa, no la suma\n",
    "    ovlp_0 = int(sum(ovlp_0))\n",
    "    return ovlp_0, ovlp_1\n",
    "\n",
    "\n",
    "#@jit(nopython=True) # The blueprint is the average of the observations (taking into account the mapping)  \n",
    "def L_wiring(A_f, P_inv_f):\n",
    "    #reconstrueix una blueprint entrenada L_new_f, prenent per cada observació la majoria mitjana\n",
    "    print(\"\\n=== DINS L_wiring ===\")\n",
    "    print(\"A_f shape:\", A_f.shape)\n",
    "    print(\"P_inv_f shape:\", P_inv_f.shape)\n",
    "    Nx = A_f.shape[1]\n",
    "    Ny = A_f.shape[2]\n",
    "    K = A_f.shape[0]\n",
    "    L_new_f = np.zeros((Nx,Ny))\n",
    "    \n",
    "    for i in range(0,Nx):\n",
    "        for j in range(0,Ny):\n",
    "            for k in range(0,K):\n",
    "        \n",
    "                p1 = int(P_inv_f[k,i]) # Mapping of the observations\n",
    "                p2 = int(P_inv_f[k,j]) # Mapping of the observations\n",
    "                L_new_f[i,j] += A_f[k,p1,p2]\n",
    "            valor_lnew=1/K* L_new_f[i,j]\n",
    "            L_new_f[i,j] = round( valor_lnew ) \n",
    "            # If valor_lnew = 0, L=0 (we could establish L=1, but it is more probable to not have a connection)\n",
    "            if i < 3 and j < 3:\n",
    "                print(f\"[{i},{j}] sum = {L_new_f[i,j]}\")\n",
    "    return L_new_f\n",
    "\n",
    "\n",
    "#### Some algorithm for sorting\n",
    "#partition i quicksort són la implementació in-place del quicksort per ordenar nodes segons grau.\n",
    "#També s’ordenen les etiquetes (array etiquetas) per mantenir el mapping.\n",
    "#@jit(nopython=True)\n",
    "def partition(array,  etiquetas, begin, end):\n",
    "    pivot = begin\n",
    "    for i in range(begin+1, end+1):\n",
    "        if array[i] < array[begin]:\n",
    "            pivot += 1\n",
    "            array[i], array[pivot] = array[pivot], array[i]\n",
    "            etiquetas[i], etiquetas[pivot] = etiquetas[pivot], etiquetas[i]\n",
    "    array[pivot], array[begin] = array[begin], array[pivot]\n",
    "    etiquetas[pivot], etiquetas[begin] = etiquetas[begin], etiquetas[pivot] \n",
    "\n",
    "    return pivot\n",
    "#@jit(nopython=True)\n",
    "def quicksort(array, etiquetas, begin=0, end=None):\n",
    "    if end is None:\n",
    "        end = len(array) - 1\n",
    "    if begin >= end: #To end\n",
    "        return\n",
    "    pivot = partition(array,  etiquetas, begin, end)\n",
    "    \n",
    "    #Order right and left\n",
    "    quicksort(array, etiquetas, begin, pivot-1)\n",
    "    quicksort(array,  etiquetas, pivot+1, end)\n",
    "    \n",
    "#@njit \n",
    "# We inizialise the algorithm sorting by node degree, but also taking into account the group labels\n",
    "def permu_groups(L_f, A_f, start_f): \n",
    "    #calcula el grau (nombre de connexions) per cada node a L_f i a cada A_f[k].\n",
    "    #ordena nodes per grau i després reordena segons start_f (grups), i construeix P_f (mapping L->A) i P_inv_f (A->L).\n",
    "    print(\"\\n=== DINS permu_groups ===\")\n",
    "    print(\"L_f shape:\", L_f.shape)\n",
    "    print(\"A_f shape:\", A_f.shape)\n",
    "\n",
    "    print(\"start_f:\", start_f)\n",
    "\n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    N_groups = len(start_f)\n",
    "    \n",
    "    \n",
    "    # Mappings\n",
    "    P_f = np.zeros((K,Nx)) #Mapping from L to A\n",
    "    P_inv_f = np.zeros((K,Nx)) #Mapping from A to L\n",
    "    P_new = np.zeros((K,Nx))\n",
    "    \n",
    "    # First we order the blueprint and after the observations\n",
    "    # Blueprint:\n",
    "    orden_L=np.zeros((Nx))\n",
    "    for i in range(Nx):\n",
    "        b=np.nonzero(L_f[i,:])\n",
    "        orden_L[i] = b[0].size\n",
    "\n",
    "    print(\"Graus L_f (primeres 10):\", orden_L[:10])\n",
    "        \n",
    "    array_L = np.arange(Nx) #For the labels \n",
    "    quicksort(orden_L, array_L)\n",
    "    \n",
    "    # Now according to the group label\n",
    "    array_L_labels = np.zeros((Nx))\n",
    "    group_number = np.zeros((N_groups))\n",
    "    for i in range(Nx):\n",
    "        n_type = 0\n",
    "        #Group\n",
    "        while ( (array_L[i] >= start_f[n_type]) and (n_type < N_groups)):\n",
    "            n_type += 1\n",
    "       \n",
    "        grupo = int(n_type-1)\n",
    "        g = int(start_f[grupo])\n",
    "        array_L_labels[g + int(group_number[grupo])] = array_L[i]\n",
    "        group_number[grupo] += 1\n",
    "\n",
    "    #Observations: \n",
    "    for i in range(0,K):\n",
    "        orden_A = np.zeros((Nx))\n",
    "        for i_orden in range(Nx):\n",
    "            b = np.nonzero(A_f[i,i_orden,:])\n",
    "            orden_A[i_orden] = b[0].size\n",
    "\n",
    "        array_A = np.arange(Nx) #For the labels \n",
    "        quicksort(orden_A, array_A)\n",
    "            \n",
    "        # Now according to the group label\n",
    "        array_A_labels = np.zeros((Nx))\n",
    "        group_number = np.zeros((N_groups))\n",
    "        \n",
    "        for i_g in range(Nx):\n",
    "            n_type = 0\n",
    "            while ( (array_A[i_g] >= start_f[n_type]) and (n_type < N_groups) ):\n",
    "                n_type += 1\n",
    "\n",
    "            grupo = int(n_type-1)\n",
    "            g = int(start_f[grupo])\n",
    "            array_A_labels[ g + int(group_number[grupo])] = array_A[i_g]\n",
    "            group_number[grupo] += 1\n",
    "    \n",
    "\n",
    "    # Now ordered together both label array  array_L = [0,1,2,3...]\n",
    "        array_A_labels = array_A_labels[np.argsort(array_L_labels)]\n",
    "        P_f[i,:] = array_A_labels\n",
    "        \n",
    "        for i_inv in range(0,Nx):\n",
    "            for j_inv in range(0,Ny):\n",
    "                if (P_f[i,i_inv] == j_inv):\n",
    "                    P_inv_f[i, j_inv]=i_inv\n",
    "    \n",
    "    P_todo = np.zeros((2,K,Nx))\n",
    "    P_todo[0,:,:] = P_f.copy() \n",
    "    P_todo[1,:,:] = P_inv_f.copy()\n",
    "\n",
    "    return P_todo\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
