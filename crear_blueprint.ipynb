{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00cfd591",
   "metadata": {},
   "source": [
    "# Crear blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e173db",
   "metadata": {},
   "source": [
    "Per verificar que datasets.ods i el notebook estan a la llista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8cb13114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable: c:\\Users\\UX433\\miniconda3\\envs\\myenv\\python.exe\n",
      "Directori de treball: c:\\Users\\UX433\\OneDrive\\Escritorio\\networkalignment\n",
      "Llistat d'arxius a la carpeta:\n",
      " - .git\n",
      " - A2_blueprint.npy\n",
      " - A_test_equiv.npy\n",
      " - C-el_k4_Synthetic- No groups - Simoultenously.ipynb\n",
      " - Hs_base0.npy\n",
      " - Hs_base1.npy\n",
      " - Hs_synthetic_paper.npy\n",
      " - L_latent_from_pq.npy\n",
      " - L_latent_repo_exact_errors.npy\n",
      " - Matriz_epochs_A.pickle\n",
      " - Syntetic_succesive_tot_0.pickle\n",
      " - codienbrut.ipynb\n",
      " - crear_blueprint.ipynb\n",
      " - datasets.ods\n",
      " - energies_base0.npy\n",
      " - energies_base1.npy\n",
      " - energy_pipeline_summary.npy\n",
      " - environment.yml\n",
      " - synthetic_paper.npy\n",
      " - synthetic_paper_0.npy\n",
      " - synthetic_repo_errors.npy\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "print(\"Python executable:\", sys.executable)     # mostra el Python que corre (ha de ser el env activat)\n",
    "print(\"Directori de treball:\", os.getcwd())    # carpeta del repo\n",
    "print(\"Llistat d'arxius a la carpeta:\")\n",
    "for f in sorted(os.listdir('.')):\n",
    "    print(\" -\", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "47175c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from numba import jit, njit\n",
    "from numba.types import bool_, int_, float32\n",
    "from math import comb\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a4265c",
   "metadata": {},
   "source": [
    "### Llegir fulls de càlcul "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2109afac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: 0 size (227, 183)\n",
      "Read: 1 size (227, 183)\n",
      "Read: 2 size (227, 183)\n",
      "Read: 3 size (227, 183)\n",
      "Read: 4 size (227, 183)\n",
      "Read: 5 size (227, 183)\n",
      "Read: 6 size (227, 183)\n",
      "Read: 7 size (227, 183)\n"
     ]
    }
   ],
   "source": [
    "### Open the files\n",
    "fulls = 8\n",
    "#n_grupo = 4 - ara no estic fent servir grups\n",
    "\n",
    "d = {} #crea un diccionari per emmagatzemar DataFrames(taules de memòria)\n",
    "D = \"Dataset\" #prefix del nom de les fulles — al excel es diuen Dataset1, Dataset2, ...\n",
    "for i in range(0,fulls): #recorro 0...7\n",
    "    d[\"group\" + str(i)] = pd.read_excel(\"datasets.ods\", sheet_name=D+str(i+1)) #el que al diccionari serà gorup 0, sera el meu Dataset1\n",
    "    # hem assignat al diccionari: d[\"group0\"] = <taula Dataset1> \n",
    "    print('Read:',i, 'size', d[\"group\" + str(i)].shape) #volem imprimir el nre de files i columnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6970a48d",
   "metadata": {},
   "source": [
    "### Passar a matriu i binaritzem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2a1aef",
   "metadata": {},
   "source": [
    "Consideracions a tenir en compte. Primer, treiem les 3 primeres files i columnes de cada full de càlcul perquè a l'excel contenen etiquetes, no dades. En segon lloc, tenim 227 diles i 183 columnes. El que fem és forçar una matriu quadrada nre.filesxnre.files, de manera que, com la matriu inicial eren zeros, copio les columnes existets i deixo la resta plenes de zeros. Això podria donar error. NOTA: Els datasets compten la primera columna com títols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9be74200",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hipermatrix M with the data (Only the synapses) \n",
    "rows = d[\"group\" + str(i)].shape[0] - 3\n",
    "columns = d[\"group\" + str(i)].shape[1] - 3 #les tres primeres files i columnes no contenen dades\n",
    "\n",
    "M = np.zeros((fulls,rows,columns))\n",
    "for i in range(0, fulls):\n",
    "    Data = d['group' + str(i)]\n",
    "    M[i,:,:] = Data.iloc[3:,3:]\n",
    "    \n",
    "## Since we work with same number of nodes, we want them equal and square (zeros when no connections)\n",
    "M_square = np.zeros((fulls, rows, rows))#creo matriu quadrada\n",
    "M_square[:,:, 0:columns] = M[:,:,:] #copies les columnes existents (0..179) per deixar zeros en les restants (180..223).\n",
    "\n",
    "## Binarization: No weights\n",
    "#Lo queremos BINARIO, ignorando su peso (Luego pensar cómo se haría con el peso)\n",
    "M_square_bin = np.zeros((fulls,rows,rows))\n",
    "for i in range(fulls):\n",
    "    for j in range(rows):\n",
    "        for k in range(columns):\n",
    "            if (M[i,j,k] >= 1):\n",
    "                M_square_bin[i,j,k] = 1\n",
    "                \n",
    "Nx = rows # Number of nodes (we imposed rows == columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38907c1",
   "metadata": {},
   "source": [
    "### Comprovació de l’estructura dels fulls de càlcul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d311e",
   "metadata": {},
   "source": [
    "Vull assegurar-me de que la neteja dels Datasets (primeres 3 files i columnes) està feta correctament. Nota: Els Datasets prenen la primera fila com un Títol  ('Pre', en aquest cas). Per tant, realment n'estic esborrant 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6a76e455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape original group7: (227, 183)\n",
      "\n",
      "Column names (first 12):\n",
      " Index(['Unnamed: 0', 'Unnamed: 1', 'Unnamed: 2', 'Pre', 'Unnamed: 4',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9',\n",
      "       'Unnamed: 10', 'Unnamed: 11'],\n",
      "      dtype='object')\n",
      "\n",
      "Primeres 8 files i 8 columnes (sense transformar):\n",
      "  Unnamed: 0 Unnamed: 1 Unnamed: 2      Pre Unnamed: 4 Unnamed: 5 Unnamed: 6  \\\n",
      "0        NaN        NaN        NaN  Sensory        NaN        NaN        NaN   \n",
      "1        NaN        NaN        NaN     ADFL       ADFR       ADLL       ADLR   \n",
      "2        NaN        NaN        NaN      NaN        NaN        NaN        NaN   \n",
      "3       Post    Sensory       ADFL        0          0          0          0   \n",
      "4        NaN        NaN       ADFR        0          0          0          0   \n",
      "5        NaN        NaN       ADLL        0          0          0          0   \n",
      "6        NaN        NaN       ADLR        0          0          0          0   \n",
      "7        NaN        NaN       AFDL        0          0          0          0   \n",
      "\n",
      "  Unnamed: 7  \n",
      "0        NaN  \n",
      "1       AFDL  \n",
      "2        NaN  \n",
      "3          0  \n",
      "4          0  \n",
      "5          0  \n",
      "6          0  \n",
      "7          0  \n"
     ]
    }
   ],
   "source": [
    "# inspecció ràpida d'un full de càlcul (group 7-->Dataset8)\n",
    "df7 = d['group7']\n",
    "print(\"Shape original group7:\", df7.shape)\n",
    "print(\"\\nColumn names (first 12):\\n\", df7.columns[:12])\n",
    "print(\"\\nPrimeres 8 files i 8 columnes (sense transformar):\")\n",
    "print(df7.iloc[:8, :8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5191d3",
   "metadata": {},
   "source": [
    "## Escollir quin és el dataset A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923ef07f",
   "metadata": {},
   "source": [
    "Sabem (per la informació del paper) que A2 té aproximadament 2186 arestes (edges), comprovem si el Dataset8 concorda amb aquestes dades, mirem cada dataset (recordem que group0-->Dataset1, group1-->Dataset2, ...).\n",
    "\n",
    "NOTA: A més sospitem que el Dataset8 és el que conté les dades de A2 perquè al repo de la Teresa es pren A2 com a Blueprint fent M_square_bin[-1] que correspon a l'últim element de l'array, és a dir, M_square_bin[7], que correspon a group7--> Dataset8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676c4042",
   "metadata": {},
   "source": [
    "### Coprovació de que Dataset8 correspon a A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7d1b9b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 775.0\n",
      "1 986.0\n",
      "2 1012.0\n",
      "3 1136.0\n",
      "4 1515.0\n",
      "5 1525.0\n",
      "6 2202.0\n",
      "7 2186.0\n"
     ]
    }
   ],
   "source": [
    "# Veure quants edges té cada dataset\n",
    "for i in range(8):\n",
    "    print(i, M_square_bin[i].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b634a9b4",
   "metadata": {},
   "source": [
    "## Guardar A2 com blueprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b610a29b",
   "metadata": {},
   "source": [
    "Volem crear i guardar el blueprint A2 (Dataset8 = group7 = M_square_bin[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0a5c5fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A2 creat\n",
      "Files i columnes A2 (224, 224)\n",
      "Arestes 2186\n",
      "Guardat com A2_blueprint\n"
     ]
    }
   ],
   "source": [
    "#Seleccionem A2, és a dir, el dataset8\n",
    "A2=M_square_bin[-1].copy()\n",
    "#Fem comprovacions\n",
    "print(\"A2 creat\")\n",
    "print(\"Files i columnes A2\", A2.shape)\n",
    "print(\"Arestes\", int(A2.sum()))\n",
    "#guardem\n",
    "np.save(\"A2_blueprint.npy\", A2)\n",
    "print(\"Guardat com A2_blueprint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463e263",
   "metadata": {},
   "source": [
    "# Generar xarxes amb error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b113626",
   "metadata": {},
   "source": [
    "Dues maneres, fixar un nombre d'errors (com es fa al codi de la Teresa) o fer servir p i q (probabilitats de copiar malament un link/no-link). Farem totes dues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbf724",
   "metadata": {},
   "source": [
    "### ESBORRAR AIXÒ: Veure d'on sortien els errors q feia servir Teresa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89bab6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges 2186 zeros 47990\n",
      "q_equiv = 0.1495882891125343\n",
      "p_equiv = 0.00681391956657637\n"
     ]
    }
   ],
   "source": [
    "L = np.load(\"A2_blueprint.npy\")\n",
    "Nx = L.shape[0]\n",
    "edges = int(L.sum())\n",
    "zeros = Nx*Nx - edges\n",
    "e_error = 327\n",
    "z_error = 327\n",
    "q_equiv = e_error / edges\n",
    "p_equiv = z_error / zeros\n",
    "print(\"edges\", edges, \"zeros\", zeros)\n",
    "print(\"q_equiv =\", q_equiv)\n",
    "print(\"p_equiv =\", p_equiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f6c5b4",
   "metadata": {},
   "source": [
    "Hem vist que p i q del repositori son practicament els mateixos del paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80ac67e",
   "metadata": {},
   "source": [
    "### Càlcul de nombre d'errors equivalents per p i q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b7136c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint A2 carregat correctament.\n",
      "Mida: (224, 224)\n",
      "Nombre d'enllaços (1’s): 2186\n"
     ]
    }
   ],
   "source": [
    "# Carrega el blueprint A2 desat\n",
    "L = np.load(\"A2_blueprint.npy\")\n",
    "\n",
    "Nx = L.shape[0]\n",
    "\n",
    "print(\"Blueprint A2 carregat correctament.\")\n",
    "print(\"Mida:\", L.shape)\n",
    "print(\"Nombre d'enllaços (1’s):\", int(L.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "304c50fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 335\n"
     ]
    }
   ],
   "source": [
    "# Errors deduits dels valors del paper\n",
    "edges_A2 = L.sum()\n",
    "zeros_A2 = Nx*Nx - edges_A2\n",
    "\n",
    "q_paper = 0.15\n",
    "p_paper = 0.007\n",
    "\n",
    "errors_esborrar = int(q_paper * edges_A2)\n",
    "errors_crear = int(p_paper * zeros_A2)\n",
    "\n",
    "print(errors_esborrar, errors_crear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc99760",
   "metadata": {},
   "source": [
    "No són exactament els mateixos, suposo que això es deu a què al repo es fan servir p i q que no quadren exactament amb els del paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c889cf9",
   "metadata": {},
   "source": [
    "(Esborrar això) ara faré el mateix però amb els p i q que he deduit del codi de la teresa, per veure si em surt el mateix nre, d'errors que ella ha fet servir (327,327) i comprovar validesa de l'anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0f0ea094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 327\n"
     ]
    }
   ],
   "source": [
    "# Errors deduits dels valors del paper\n",
    "edges_A2 = L.sum()\n",
    "zeros_A2 = Nx*Nx - edges_A2\n",
    "\n",
    "errors_esborrar_teresa = int(q_equiv * edges_A2)\n",
    "errors_crear_teresa = int(p_equiv * zeros_A2)\n",
    "\n",
    "print(errors_esborrar_teresa, errors_crear_teresa)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4fec7",
   "metadata": {},
   "source": [
    "Sí, el nombre d'errors quadra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822fdf74",
   "metadata": {},
   "source": [
    "# Generar xarxes amb nombre d'errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf29cec",
   "metadata": {},
   "source": [
    "Ara estem generant xarxes com es feia al repositori, amb el mateix nombre d'errors exacte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fddc963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# === Generar xarxes amb errors exactes (estil del repo) ===\\n\\nK = 2             # nombre de xarxes a generar\\ne_error = 327       # errors esborrant enllaços\\nz_error = 327       # errors creant enllaços\\n\\n# Carregar blueprint si cal\\nif \\'L\\' not in globals():\\n    print(\"No hi ha L a la memòria, carregant A2_blueprint.npy ...\")\\n    L = np.load(\"A2_blueprint.npy\")\\n\\nNx = L.shape[0]\\nprint(\"Blueprint A2 carregat: shape\", L.shape, \"edges:\", int(L.sum()))\\n\\n# Preparar output\\nA_repo = np.zeros((K, Nx, Nx), dtype=int)\\nrng = np.random.default_rng(42)  # llavor fixa\\n\\nedges_total = int(L.sum())\\nzeros_total = Nx * Nx - edges_total\\n\\nprint(\"Edges A2:\", edges_total, \"Zeros A2:\", zeros_total)\\n\\n# Comprovacions\\nif e_error > edges_total:\\n    raise ValueError(f\"e_error ({e_error}) > nombre d\\'enllaços ({edges_total})\")\\nif z_error > zeros_total:\\n    raise ValueError(f\"z_error ({z_error}) > nombre de zeros ({zeros_total})\")\\n\\nfor m in range(K):\\n    A = L.copy().astype(int)\\n    A_flat = A.reshape(Nx*Nx)\\n\\n    ones_idx = np.where(A_flat == 1)[0]\\n    zeros_idx = np.where(A_flat == 0)[0]\\n\\n    flip_ones = rng.choice(ones_idx, size=e_error, replace=False)\\n    flip_zeros = rng.choice(zeros_idx, size=z_error, replace=False)\\n\\n    A_flat[flip_ones] = 0\\n    A_flat[flip_zeros] = 1\\n\\n    A = A_flat.reshape(Nx, Nx)\\n    A_repo[m] = A\\n\\n    errors_removed = edges_total - np.sum((A == 1) & (L == 1))\\n    errors_added = np.sum((A == 1) & (L == 0))\\n\\n    print(f\"Xarxa {m}: Edges = {int(A.sum())}, Errors esborrant = {errors_removed}, Errors creant = {errors_added}\")\\n\\n# Guardar a disc\\nout_name = \"synthetic_repo_errors.npy\"\\nnp.save(out_name, A_repo)\\nprint(\"\\nGuardades les xarxes amb errors exactes a:\", out_name)\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# === Generar xarxes amb errors exactes (estil del repo) ===\n",
    "\n",
    "K = 2             # nombre de xarxes a generar\n",
    "e_error = 327       # errors esborrant enllaços\n",
    "z_error = 327       # errors creant enllaços\n",
    "\n",
    "# Carregar blueprint si cal\n",
    "if 'L' not in globals():\n",
    "    print(\"No hi ha L a la memòria, carregant A2_blueprint.npy ...\")\n",
    "    L = np.load(\"A2_blueprint.npy\")\n",
    "\n",
    "Nx = L.shape[0]\n",
    "print(\"Blueprint A2 carregat: shape\", L.shape, \"edges:\", int(L.sum()))\n",
    "\n",
    "# Preparar output\n",
    "A_repo = np.zeros((K, Nx, Nx), dtype=int)\n",
    "rng = np.random.default_rng(42)  # llavor fixa\n",
    "\n",
    "edges_total = int(L.sum())\n",
    "zeros_total = Nx * Nx - edges_total\n",
    "\n",
    "print(\"Edges A2:\", edges_total, \"Zeros A2:\", zeros_total)\n",
    "\n",
    "# Comprovacions\n",
    "if e_error > edges_total:\n",
    "    raise ValueError(f\"e_error ({e_error}) > nombre d'enllaços ({edges_total})\")\n",
    "if z_error > zeros_total:\n",
    "    raise ValueError(f\"z_error ({z_error}) > nombre de zeros ({zeros_total})\")\n",
    "\n",
    "for m in range(K):\n",
    "    A = L.copy().astype(int)\n",
    "    A_flat = A.reshape(Nx*Nx)\n",
    "\n",
    "    ones_idx = np.where(A_flat == 1)[0]\n",
    "    zeros_idx = np.where(A_flat == 0)[0]\n",
    "\n",
    "    flip_ones = rng.choice(ones_idx, size=e_error, replace=False)\n",
    "    flip_zeros = rng.choice(zeros_idx, size=z_error, replace=False)\n",
    "\n",
    "    A_flat[flip_ones] = 0\n",
    "    A_flat[flip_zeros] = 1\n",
    "\n",
    "    A = A_flat.reshape(Nx, Nx)\n",
    "    A_repo[m] = A\n",
    "\n",
    "    errors_removed = edges_total - np.sum((A == 1) & (L == 1))\n",
    "    errors_added = np.sum((A == 1) & (L == 0))\n",
    "\n",
    "    print(f\"Xarxa {m}: Edges = {int(A.sum())}, Errors esborrant = {errors_removed}, Errors creant = {errors_added}\")\n",
    "\n",
    "# Guardar a disc\n",
    "out_name = \"synthetic_repo_errors.npy\"\n",
    "np.save(out_name, A_repo)\n",
    "print(\"\\nGuardades les xarxes amb errors exactes a:\", out_name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f92add2",
   "metadata": {},
   "source": [
    "# Generar xarxes amb p i q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b840586",
   "metadata": {},
   "source": [
    "Ara volem comprovar el nombre d'enllaços que s'han creat (p·zeros ≈ 0.007·48000 ≈ 330–350 nous) i esborrat (q·edges ≈ 0.15·2186 ≈ 327–330 enllaços)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a40bf",
   "metadata": {},
   "source": [
    "El que estic fent aquí no és modificar el blueprint amb errors, no reconstruir des de 0. No estic recreant la matriu probabilisticament partint d'una matriu de 0s. \n",
    "Aqui la matriu L comença tocada i només altero alguns elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f9447b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xarxes generades amb p i q del paper:\n",
      "(2, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "num_networks = 2\n",
    "A_test = np.zeros((num_networks, Nx, Nx)) #crea un array 3D ple de zeros\n",
    "\n",
    "p = p_paper\n",
    "q = q_paper\n",
    "\n",
    "np.random.seed(1) #fixo la llavor de les xarxes random generades pq sino cada execucio em genera xarxes diferents\n",
    "\n",
    "for k in range(num_networks):\n",
    "    A_copy = L.copy() #deep copy de L, però no comparteixen memòria. modificar a.copy no modifica L\n",
    "    for i in range(Nx):\n",
    "        for j in range(Nx):\n",
    "            if L[i,j] == 1:\n",
    "                # enllaç existent -> pot ser esborrat\n",
    "                if np.random.rand() < q: #genero aleatori entre 0 i 1\n",
    "                    A_copy[i,j] = 0\n",
    "            else:\n",
    "                # posició buida -> pot crear-se un fals\n",
    "                if np.random.rand() < p:\n",
    "                    A_copy[i,j] = 1\n",
    "    A_test[k,:,:] = A_copy #guardo cada xarxa k generada.\n",
    "    # per cada k (ie per cada xarxa), es comença de zero fent una còpia nova i completa de L.\n",
    "\n",
    "\n",
    "print(\"Xarxes generades amb p i q del paper:\")\n",
    "print(A_test.shape)\n",
    "np.save(\"synthetic_paper.npy\", A_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb6fa2",
   "metadata": {},
   "source": [
    "Si ho vull fer tal com em va dir la marta, emplenant una matriu feta de 0s seria aixi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49a162bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xarxes generades amb p i q del paper partint d'una de 0s (recrear probabilisticament):\n",
      "(2, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "A_test_0 = np.zeros((num_networks, Nx, Nx))\n",
    "np.random.seed(1)\n",
    "\n",
    "for k in range(num_networks):\n",
    "    A_copy_0 = np.zeros_like(L)   # matriu tota de 0\n",
    "\n",
    "    for i in range(Nx):\n",
    "        for j in range(Nx):\n",
    "\n",
    "            if L[i, j] == 1:\n",
    "                # Enllaç existent\n",
    "                if np.random.rand() < q:\n",
    "                    A_copy_0[i, j] = 0        # No copio (error d'esborrat)\n",
    "                else:\n",
    "                    A_copy_0[i, j] = 1        # Copio\n",
    "            else:\n",
    "                # No enllaç\n",
    "                if np.random.rand() < p:\n",
    "                    A_copy_0[i, j] = 1        # Fals positiu\n",
    "                else:\n",
    "                    A_copy_0[i, j] = 0        # Copio (0)\n",
    "\n",
    "    A_test_0[k] = A_copy_0\n",
    "print(\"Xarxes generades amb p i q del paper partint d'una de 0s (recrear probabilisticament):\")\n",
    "print(A_test_0.shape)\n",
    "np.save(\"synthetic_paper_0.npy\", A_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b0c980c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blueprint (A2) edges: 2186\n",
      "Blueprint zeros: 47990\n",
      "\n",
      "Xarxa 0:\n",
      "  Edges: 2207\n",
      "  Errors esborrant: 320\n",
      "  Errors creant: 341\n",
      "\n",
      "Xarxa 1:\n",
      "  Edges: 2174\n",
      "  Errors esborrant: 333\n",
      "  Errors creant: 321\n"
     ]
    }
   ],
   "source": [
    "# Comprovació del nombre d’enllaços final\n",
    "original_edges = int(L.sum())\n",
    "zeros_original = Nx*Nx - original_edges\n",
    "\n",
    "print(\"Blueprint (A2) edges:\", original_edges)\n",
    "print(\"Blueprint zeros:\", zeros_original)\n",
    "\n",
    "for k in range(num_networks):\n",
    "    edges_new = int(A_test[k].sum())\n",
    "    print(f\"\\nXarxa {k}:\")\n",
    "    print(\"  Edges:\", edges_new)\n",
    "\n",
    "    # errors equivalents\n",
    "    errors_esborrats = original_edges - np.sum((A_test[k] == 1) & (L == 1))\n",
    "    errors_creats = np.sum((A_test[k] == 1) & (L == 0))\n",
    "\n",
    "    print(\"  Errors esborrant:\", errors_esborrats)\n",
    "    print(\"  Errors creant:\", errors_creats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c7afe",
   "metadata": {},
   "source": [
    "## Funcions d'energia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6df48",
   "metadata": {},
   "source": [
    "Aquí enganxo les funcions d'energia del repositori del paper, del notebook \"C-el_k4_Synthetic-No groups...\", ja que son les mateixes que he de fer servir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47311f22",
   "metadata": {},
   "source": [
    "No considerem grups, per tant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a3e81b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_groups = 1 #considerem que els nodes pertanyen a un únic grup\n",
    "start_groups = np.zeros(1) #indica on comença cada grup\n",
    "end_groups = np.zeros(1) + Nx #indica on acaba\n",
    "size_groups = np.zeros(1) + Nx\n",
    "\n",
    "start_groups, end_groups, size_groups = start_groups.astype(int), end_groups.astype(int), size_groups.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d37d46",
   "metadata": {},
   "source": [
    "Aquestes son les funcions d'energia tal qual com estan al repo del paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6cfd7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta):\n",
    "\n",
    "    A_1 = overlap_1 + alpha\n",
    "    B_1 = (Edges_L - overlap_1 + beta)\n",
    "    C_1 = Edges_L + alpha + beta\n",
    "    \n",
    "    A_0 = overlap_0 + alpha\n",
    "    B_0 = (Edges_NoL - overlap_0 + beta)\n",
    "    C_0 = Edges_NoL + alpha + beta\n",
    "    \n",
    "    #  [ math.lgamma(n+1) == log(n!) ]\n",
    "    H1 = math.lgamma(A_1)+ math.lgamma(B_1) - math.lgamma(C_1) \n",
    "    H0 = math.lgamma(A_0)+ math.lgamma(B_0) - math.lgamma(C_0) \n",
    "    \n",
    "    H = -(H1 + H0)\n",
    "    return H\n",
    "    \n",
    "    \n",
    "@jit(nopython=True)\n",
    "def overlap_total_prob(L_f, A_f, P_inv_f):\n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    \n",
    "    ovlp_0 = np.zeros((K))\n",
    "    ovlp_1 = np.zeros((K))\n",
    "    for k in range(0,K):\n",
    "        for f in range(0,Ny): \n",
    "            for c in range(0,Nx):\n",
    "                p_f=int(P_inv_f[k,f])\n",
    "                p_c=int(P_inv_f[k,c])  \n",
    "                \n",
    "                valor_L, valor_A = L_f[f,c], A_f[k,p_f,p_c]\n",
    "                \n",
    "                ovlp_0[k] = ovlp_0[k] + (1-valor_L)*(1-valor_A )\n",
    "                ovlp_1[k] = ovlp_1[k] + valor_L*valor_A\n",
    "                \n",
    "                \n",
    "    ovlp_1 = int(sum(ovlp_1))\n",
    "    ovlp_0 = int(sum(ovlp_0))\n",
    "    return ovlp_0, ovlp_1\n",
    "\n",
    "\n",
    "@jit(nopython=True) # The blueprint is the average of the observations (taking into account the mapping)  \n",
    "def L_wiring(A_f, P_inv_f):\n",
    "    \n",
    "    Nx = A_f.shape[1]\n",
    "    Ny = A_f.shape[2]\n",
    "    K = A_f.shape[0]\n",
    "    L_new_f = np.zeros((Nx,Ny))\n",
    "    \n",
    "    for i in range(0,Nx):\n",
    "        for j in range(0,Ny):\n",
    "            for k in range(0,K):\n",
    "        \n",
    "                p1 = int(P_inv_f[k,i]) # Mapping of the observations\n",
    "                p2 = int(P_inv_f[k,j]) # Mapping of the observations\n",
    "                L_new_f[i,j] += A_f[k,p1,p2]\n",
    "            valor_lnew=1/K* L_new_f[i,j]\n",
    "            L_new_f[i,j] = round( valor_lnew ) \n",
    "            # If valor_lnew = 0, L=0 (we could establish L=1, but it is more probable to not have a connection)\n",
    "    \n",
    "    return L_new_f\n",
    "\n",
    "\n",
    "#### Some algorithm for sorting\n",
    "@jit(nopython=True)\n",
    "def partition(array,  etiquetas, begin, end):\n",
    "    pivot = begin\n",
    "    for i in range(begin+1, end+1):\n",
    "        if array[i] < array[begin]:\n",
    "            pivot += 1\n",
    "            array[i], array[pivot] = array[pivot], array[i]\n",
    "            etiquetas[i], etiquetas[pivot] = etiquetas[pivot], etiquetas[i]\n",
    "    array[pivot], array[begin] = array[begin], array[pivot]\n",
    "    etiquetas[pivot], etiquetas[begin] = etiquetas[begin], etiquetas[pivot] \n",
    "\n",
    "    return pivot\n",
    "@jit(nopython=True)\n",
    "def quicksort(array, etiquetas, begin=0, end=None):\n",
    "    if end is None:\n",
    "        end = len(array) - 1\n",
    "    if begin >= end: #To end\n",
    "        return\n",
    "    pivot = partition(array,  etiquetas, begin, end)\n",
    "    \n",
    "    #Order right and left\n",
    "    quicksort(array, etiquetas, begin, pivot-1)\n",
    "    quicksort(array,  etiquetas, pivot+1, end)\n",
    "    \n",
    "@njit \n",
    "# We inizialise the algorithm sorting by node degree, but also taking into account the group labels\n",
    "def permu_groups(L_f, A_f, start_f): \n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    N_groups = len(start_f)\n",
    "    \n",
    "    \n",
    "    # Mappings\n",
    "    P_f = np.zeros((K,Nx)) #Mapping from L to A\n",
    "    P_inv_f = np.zeros((K,Nx)) #Mapping from A to L\n",
    "    P_new = np.zeros((K,Nx))\n",
    "    \n",
    "    # First we order the blueprint and after the observations\n",
    "    # Blueprint:\n",
    "    orden_L=np.zeros((Nx))\n",
    "    for i in range(Nx):\n",
    "        b=np.nonzero(L_f[i,:])\n",
    "        orden_L[i] = b[0].size\n",
    "        \n",
    "    array_L = np.arange(Nx) #For the labels \n",
    "    quicksort(orden_L, array_L)\n",
    "    \n",
    "    # Now according to the group label\n",
    "    array_L_labels = np.zeros((Nx))\n",
    "    group_number = np.zeros((N_groups))\n",
    "    for i in range(Nx):\n",
    "        n_type = 0\n",
    "        #Group\n",
    "        while ( (array_L[i] >= start_f[n_type]) and (n_type < N_groups)):\n",
    "            n_type += 1\n",
    "       \n",
    "        grupo = int(n_type-1)\n",
    "        g = int(start_f[grupo])\n",
    "        array_L_labels[g + int(group_number[grupo])] = array_L[i]\n",
    "        group_number[grupo] += 1\n",
    "\n",
    "    #Observations: \n",
    "    for i in range(0,K):\n",
    "        orden_A = np.zeros((Nx))\n",
    "        for i_orden in range(Nx):\n",
    "            b = np.nonzero(A_f[i,i_orden,:])\n",
    "            orden_A[i_orden] = b[0].size\n",
    "\n",
    "        array_A = np.arange(Nx) #For the labels \n",
    "        quicksort(orden_A, array_A)\n",
    "            \n",
    "        # Now according to the group label\n",
    "        array_A_labels = np.zeros((Nx))\n",
    "        group_number = np.zeros((N_groups))\n",
    "        \n",
    "        for i_g in range(Nx):\n",
    "            n_type = 0\n",
    "            while ( (array_A[i_g] >= start_f[n_type]) and (n_type < N_groups) ):\n",
    "                n_type += 1\n",
    "\n",
    "            grupo = int(n_type-1)\n",
    "            g = int(start_f[grupo])\n",
    "            array_A_labels[ g + int(group_number[grupo])] = array_A[i_g]\n",
    "            group_number[grupo] += 1\n",
    "    \n",
    "\n",
    "    # Now ordered together both label array  array_L = [0,1,2,3...]\n",
    "        array_A_labels = array_A_labels[np.argsort(array_L_labels)]\n",
    "        P_f[i,:] = array_A_labels\n",
    "        \n",
    "        for i_inv in range(0,Nx):\n",
    "            for j_inv in range(0,Ny):\n",
    "                if (P_f[i,i_inv] == j_inv):\n",
    "                    P_inv_f[i, j_inv]=i_inv\n",
    "    \n",
    "    P_todo = np.zeros((2,K,Nx))\n",
    "    P_todo[0,:,:] = P_f.copy() \n",
    "    P_todo[1,:,:] = P_inv_f.copy()\n",
    "\n",
    "    return P_todo\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f937217f",
   "metadata": {},
   "source": [
    "## Generar 10 mostres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc543336",
   "metadata": {},
   "source": [
    "El que vull fer ara és agafar la blueprint i les dues xarxes generades i aplicar la identitat i les funcions d'energia. Després, fer un shuffle i aplicar energies. Generar 10 i fer historigrama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9674ba",
   "metadata": {},
   "source": [
    "### pas 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9f0af9",
   "metadata": {},
   "source": [
    "De moment agafo la latent, i les dues xarxes generades amb cert error i aplico identitat i funcions d'energia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7adc8e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeres 6 posicions de la primera fila del vector identitat, han de sortir en ordre [0 1 2 3 4 5]\n",
      "Aplico L_wiring\n",
      "L_nova shape: (224, 224)\n",
      "Similitud entre L y L_nova: 49559 de 50176\n",
      "Aplico overlap_total_prob\n",
      "ovlp0_identity = 95318\n",
      "ovlp1_identity = 3719\n",
      "Edges_L  = 2186\n",
      "Edges_NoL = 47990\n",
      "alpha = 1.0  beta = 1.0\n",
      "Aplico hamiltonian_prob\n",
      "H_identity = -inf\n",
      "PAS 1 complet correctament.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#carrego fitxers\n",
    "L = np.load(\"A2_blueprint.npy\")                   # blueprint guardada\n",
    "A_test = np.load(\"synthetic_paper.npy\")           # 2 xarxes generades\n",
    "\n",
    "\n",
    "# Construir Ao_stack i identitat (P_inv_id)\n",
    "Ao_enters = A_test.astype(int)       # aqui convertim a int per si de cas havia quedat amb floats després de fer rand\n",
    "P_inv_id = np.tile(np.arange(Nx), (K,1)).astype(int)   #fem k vectors identitat, perquè les funcions defineixen les permutacions com vectors de mmida NX, no matrius\n",
    "\n",
    "print(\"Primeres 6 posicions de la primera fila del vector identitat, han de sortir en ordre\", P_inv_id[0,:6])\n",
    "\n",
    "#ara tinc:\n",
    "#L → la blueprint (matriu binaria 224x224)\n",
    "#A_test → les dues xarxes q he generat abans amb p i q(forma 2×224×224)\n",
    "#P_inv_id → perm identitat (0,1,2,…,223), feta dos cops (per les dues xarxes)'''\n",
    "\n",
    "#Cridar L_wiring sobre Ao_stack amb identitat, aixo em dona tot 0s, aixiq  ha d'estar malament\n",
    "print(\"Aplico L_wiring\")\n",
    "L_nova = L_wiring(Ao_enters, P_inv_id)\n",
    "print(\"L_nova shape:\", L_nova.shape)\n",
    "\n",
    "#comprovar si L_nova és igual a L\n",
    "print(\"Similitud entre L y L_nova:\", np.sum(L == L_nova), \"de\", Nx*Nx)\n",
    "#si no surt 50176 de 50176, vol dir que L_wiring no està funcionant bé.\n",
    "\n",
    "\n",
    "#Cridar overlap_total_prob amb la blueprint original (L) i Ao_stack amb identitat\n",
    "print(\"Aplico overlap_total_prob\")\n",
    "ovlp0_identity, ovlp1_identity = overlap_total_prob(L, Ao_enters, P_inv_id)\n",
    "print(\"ovlp0_identity =\", ovlp0_identity)\n",
    "print(\"ovlp1_identity =\", ovlp1_identity) \n",
    "\n",
    "#un valor raonable seria tenir ovlp1_identity proper al nombre d'enllaços menys els errors esborrant, i ovlp0_identity proper al nombre de zeros menys els errors creant.\n",
    "#com la majoria eres zeros, ovlp0_identity ha de ser molt gran, i ovlp1_identity ha de ser menor però proper al nombre d'enllaços menys els errors esborrant(menor que 2186).\n",
    "#dona valors inconsistents, per tant alguna cosa no està funcionant bé.\n",
    "\n",
    "#aplico hamiltonian_prob\n",
    "# Calcular nombre d'enllaços i zeros a la blueprint\n",
    "Nx = L.shape[0]\n",
    "Edges_L = int(L.sum())                 # nombre de 1s de la blueprint, hauria de ser 2186\n",
    "Edges_NoL = Nx*Nx - Edges_L            # nombre de 0s\n",
    "\n",
    "print(\"Edges_L  =\", Edges_L)\n",
    "print(\"Edges_NoL =\", Edges_NoL)\n",
    "\n",
    "#Parametres alpha i beta\n",
    "alpha = 1.0\n",
    "beta  = 1.0\n",
    "print(\"alpha =\", alpha, \" beta =\", beta)\n",
    "\n",
    "# Aplicar hamiltonian_prob\n",
    "print(\"Aplico hamiltonian_prob\")\n",
    "H_identity = hamiltonian_prob(\n",
    "    Edges_NoL,\n",
    "    Edges_L,\n",
    "    ovlp0_identity,\n",
    "    ovlp1_identity,\n",
    "    alpha,\n",
    "    beta\n",
    ")\n",
    "\n",
    "print(\"H_identity =\", H_identity)\n",
    "\n",
    "#Guardar resultats, descomento quan estig segura que funciona\n",
    "#np.save(\"H_identity.npy\", np.array(H_identity))\n",
    "#np.save(\"ovlp0_identity.npy\", np.array(ovlp0_identity))\n",
    "#np.save(\"ovlp1_identity.npy\", np.array(ovlp1_identity))\n",
    "\n",
    "print(\"PAS 1 complet correctament.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
